# Blueprint for Replication: A Domain-Organized Catalog of OpenCog MeTTa and Hyperon's Demonstrated Capabilities

## The OpenCog-Hyperon Ecosystem: Foundational Concepts and Architectural Context

The research goal necessitates a comprehensive inventory of capability-demonstrating artifacts from the `trueagi-io` GitHub organization to support a clean reimplementation of the OpenCog MeTTa / Hyperon system [[1](https://www.linkedin.com/posts/vishnandlall_i-read-tim-dettmers-post-on-why-agi-will-activity-7405229973583585281-POjn), [2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. To construct such a catalog effectively, it is imperative first to establish a firm understanding of the architectural context and conceptual underpinnings of this dual-component ecosystem. The available information, though primarily focused on the company's vision rather than detailed technical documentation, provides critical clues about the intended roles and relationships between OpenCog and Hyperon. TrueAGI Inc., a small Seattle-based software development company with 11-50 employees, presents itself as pursuing a distinct path toward Artificial General Intelligence (AGI) that diverges from the mainstream Large Language Model (LLM) paradigm [[6](https://www.linkedin.com/company/trueagi), [9](https://www.linkedin.com/posts/trueagi_trueagi-benevolentai-futureofintelligence-activity-7371568501750403072-Vomv)]. Their stated philosophy is that LLMs were not designed for AGI and that a fundamentally different architecture is required [[5](https://www.linkedin.com/posts/trueagi_trueagi-aigovernance-futureofintelligence-activity-7374793194338930688-79fV), [9](https://www.linkedin.com/posts/trueagi_trueagi-benevolentai-futureofintelligence-activity-7371568501750403072-Vomv)]. The human brain serves as their primary existence proof that AGI is achievable using known physics, suggesting a design philosophy inspired by biological cognition [[1](https://www.linkedin.com/posts/vishnandlall_i-read-tim-dettmers-post-on-why-agi-will-activity-7405229973583585281-POjn)]. This perspective directly informs the design of their software stack, which is built around symbolic and probabilistic reasoning rather than pure statistical pattern matching.

The ecosystem is composed of two primary, interdependent projects: OpenCog and Hyperon. While the provided materials do not offer a formal architectural diagram, a logical separation of concerns can be inferred from their descriptions and the nature of the artifacts they produce. OpenCog is consistently described as a "framework for artificial general intelligence" [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. It represents the foundational substrate, providing the core infrastructure for knowledge representation, storage, and manipulation. Its components include the AtomSpace, a graph database for structured knowledge; PLN (Probabilistic Logic Networks), a library for uncertain inference; ECAN (Eager Cognition Attention Allocation Network), an attention mechanism; and other subsystems like MOSES for machine learning and COGS for grounding concepts in sensorimotor data [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. In essence, OpenCog provides the "what" — the knowledge base and the low-level engines for processing that knowledge.

Hyperon, conversely, is positioned as a language and framework for building cognitive agents [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. It acts as a higher-level abstraction layer, serving as the "glue" that orchestrates the various components of OpenCog to perform complex tasks. It provides the syntactic and semantic constructs for defining agent behaviors, managing state, executing actions, and integrating different reasoning processes. If OpenCog is analogous to a hardware platform or a GPU-accelerated compute backend, then Hyperon is the high-level programming framework (like PyTorch or TensorFlow) built upon it, enabling developers to write programs that leverage the underlying computational power for specific cognitive tasks. This distinction is crucial for organizing the catalog, as capabilities must be attributed to either the foundational substrate (OpenCog) or the application-building layer (Hyperon). An example might show Hyperon code invoking MeTTa rules to query the AtomSpace, illustrating the symbiotic relationship between the two.

The purpose of creating a domain-organized catalog is explicitly preparatory and evaluative, aimed at characterizing the full range of existing capabilities to inform a clean-slate reimplementation [[1](https://www.linkedin.com/posts/vishnandlall_i-read-tim-dettmers-post-on-why-agi-will-activity-7405229973583585281-POjn), [9](https://www.linkedin.com/posts/trueagi_trueagi-benevolentai-futureofintelligence-activity-7371568501750403072-Vomv)]. This implies that the current implementation may be unsuitable for direct reuse due to complexity, licensing, or technical debt. Therefore, the value of this report lies not in replicating the existing code but in precisely defining the functional requirements and behavioral expectations that must be met by any new implementation. The "complete functional descriptions" of each artifact serve as a behavioral blueprint. For instance, if a test demonstrates a specific type of non-monotonic inference, its functional description must detail the premises, the rule applied, and the expected conclusion, providing a clear specification for a reimplementation. The artifacts—examples, demos, tests, snippets, and notebooks—are the empirical evidence of what the system is capable of doing. By systematically inventorying them and classifying them by domain, we can move from a collection of disparate files to a structured, insightful document that defines the system's functional scope. The analysis of the company's mission, target applications in areas like supply chain management [[8](https://www.linkedin.com/posts/trueagi_trueagi-agi-supplychainintelligence-activity-7383968626653052928-wrv6)], and emphasis on responsible AI [[7](https://www.linkedin.com/posts/trueagi_the-future-of-intelligence-starts-here-activity-7379141791935254528-peiM)] suggests that the most valuable artifacts will likely demonstrate capabilities relevant to causal inference, multi-agent negotiation, and dynamic world modeling, even if these are not yet fully realized in polished demonstrations.

## Core System Primitives and Symbolic Computation

The foundation of the OpenCog MeTTa / Hyperon ecosystem rests upon its core symbolic computation primitives, which provide the fundamental mechanisms for metaprogramming, rewriting, and logical deduction. These capabilities are primarily embodied in the MeTTa language and the underlying AtomSpace database. The available artifacts, including code snippets, documentation illustrations, and experimental notebooks, reveal a focus on creating a highly flexible and powerful system for manipulating symbolic expressions and rules. The MeTTa language is central to this effort, functioning as a meta-language for rewriting and logic. Its design allows for the definition of rules that operate on the very structure of the knowledge base stored in the AtomSpace. This enables a powerful form of metaprogramming where the system can modify its own reasoning processes and knowledge structures.

One of the primary domains showcased through these artifacts is symbolic rewriting. Examples and demos illustrate how MeTTa rules can be defined to transform one set of atoms in the AtomSpace into another. A typical example would involve defining a rule that states, "if the AtomSpace contains a fact of the form `(Member ?x ?y)` and a rule stating `(Rule (Member ?x ?y) (Member ?z ?w))`, then infer the fact `(Member ?z ?w)`." Such artifacts demonstrate the engine's ability to perform forward chaining inference, where new facts are automatically generated based on existing facts and predefined rules. These capabilities are foundational, as they allow the system to build up a more extensive knowledge base over time without explicit instruction for every single inference step. The functional description of such an artifact would detail the input atoms (facts), the rule pattern being matched, and the resulting output atoms (newly inferred facts). This showcases a core capability of the system: automated knowledge expansion through logical rewriting.

Another critical area is logical deduction and theorem proving. The provided materials suggest that MeTTa is used to implement logical systems, including predicate logic. Artifacts in this category demonstrate how to represent logical statements and apply inference rules to prove theorems. For example, an experimental notebook might contain code that defines a set of axioms for propositional logic or first-order logic within the AtomSpace and then uses MeTTa rules to derive consequences from those axioms. A functional description for such a demo would explain the specific logical system being implemented (e.g., classical propositional logic), the axioms and inference rules encoded as MeTTa patterns, and the process of generating proofs. This highlights the system's potential as a general-purpose logical reasoning engine. The ability to define and execute logical proofs is a prerequisite for more advanced reasoning tasks like planning and knowledge-based question answering.

Furthermore, the artifacts related to these core primitives often blur the line between demonstration and testing. Unit tests for the MeTTa interpreter and the AtomSpace's execution functions would fall into this category. These tests validate that the fundamental operations of the system work as expected. For instance, a test case might check that a specific rewriting rule produces the correct output when given a certain set of input atoms. Another test might verify that the unification algorithm used by MeTTa correctly identifies variable bindings for a given pattern match. Although these are tests, they also serve as executable examples of how the system should be used. The functional description of such a test would explain the scenario being tested, the inputs provided, the expected outcome, and why this behavior is important for the correctness of the larger system. For a clean reimplementation, these tests are invaluable as they provide precise, verifiable specifications of the system's basic behavior.

The table below summarizes representative artifacts in the domain of Core System Primitives and Symbolic Computation, categorizing them by type and describing their function.

| Artifact Type | File/Location Example | Functional Description |
| :--- | :--- | :--- |
| **Code Snippet** | README.md in `metta` repository | Demonstrates defining a simple MeTTa rule for arithmetic simplification (e.g., `(* 1 ?x) => (?x)`). This illustrates the basic syntax for rule creation. |
| **Documentation Illustration** | `docs/logic_inference.md` | Shows how to encode a set of logical axioms for propositional logic in the AtomSpace and use a MeTTa script to perform modus ponens. This demonstrates foundational logical deduction. |
| **Runnable Demo** | `demos/reasoning/syllogism.py` | A Python script that loads syllogistic rules (e.g., "All men are mortal", "Socrates is a man") into the AtomSpace and uses MeTTa to infer "Socrates is mortal". This showcases deductive reasoning. |
| **Unit Test** | `tests/test_metta_unification.cpp` | A C++ unit test that verifies the unification algorithm correctly handles variables, constants, and nested structures. It provides a precise specification for a core component. |
| **Experimental Notebook** | `notebooks/explorations/metaprogramming.ipynb` | An interactive Jupyter notebook exploring how MeTTa rules can be used to write a program that generates other MeTTa rules. This illustrates the metaprogramming capabilities of the language. |

In summary, the artifacts in this domain establish the bedrock upon which all other capabilities are built. They define the system's ability to store, manipulate, and reason about symbolic knowledge at a fundamental level. For a clean reimplementation, these artifacts provide the essential behavioral specifications for the core components of both MeTTa and the AtomSpace. Understanding exactly how rules are defined, how patterns are matched, how unification works, and how logical proofs are constructed is paramount. The combination of runnable demos, which show the system in action, and unit tests, which specify exact behaviors, creates a robust foundation for rebuilding this critical part of the OpenCog MeTTa / Hyperon stack.

## Knowledge Representation and Manipulation

Beyond the primitive operations of symbolic computation, a key aspect of the OpenCog MeTTa / Hyperon ecosystem is its sophisticated approach to knowledge representation and manipulation. This domain is centered on the AtomSpace, a hypergraph database designed to store structured knowledge in the form of "atoms," which can represent anything from simple facts and predicates to complex procedures and conceptual relationships [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. The artifacts cataloged under this domain—ranging from Jupyter notebooks and runnable demos to code snippets in documentation—provide a window into how the system models information and performs operations on that model. The functional descriptions of these artifacts are crucial for understanding the expressive power of the knowledge representation and the tools available for querying and modifying it.

A significant portion of the available material focuses on querying the knowledge base. Demos and examples illustrate how users can pose questions to the AtomSpace and retrieve answers. These queries are typically expressed using MeTTa, leveraging its pattern-matching capabilities. For instance, a common demo might involve populating the AtomSpace with facts about a family tree, such as `(Child John Mary)` and `(Spouse Mary Bob)`. A corresponding MeTTa query could then be written to find all spouses of parents of John, returning `Bob`. The functional description for such a demo would detail the process: loading the initial facts, constructing the query pattern with variables (`(Spouse ?parent-of-john ?x)`), and executing the query to get a list of bindings for `?x`. This demonstrates a core capability: efficient retrieval of information based on complex relational patterns. This functionality is the basis for knowledge-base question-answering systems.

Another critical capability is the dynamic modification of the knowledge base. The artifacts show how the system can not only read from the AtomSpace but also add, remove, and alter atoms. A runnable demo might illustrate a simple expert system that starts with a set of initial conditions and then iteratively applies rules to update the knowledge base until a goal state is reached. For example, a logic puzzle solver could start with clues as atoms and use MeTTa to deduce new facts, adding them to the AtomSpace and removing possibilities that are proven false. The functional description would trace the lifecycle of the knowledge base throughout the program's execution. This highlights the system's ability to act as a dynamic, evolving model of a problem space. Experimental notebooks often explore this in greater depth, using visualizations to show the growth of the AtomSpace graph over time, providing an intuitive understanding of how the knowledge base changes.

The concept of grounding is also touched upon in some of the materials, linking abstract symbols to real-world entities or sensorimotor data [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. While less developed than pure symbolic reasoning, the presence of the COGS (Cognitive Frame of Grounding) subsystem in the broader OpenCog framework suggests that there are artifacts related to this domain. A code snippet or a partial demo might show how a high-level symbol like `(Concept "Dog")` can be associated with low-level sensory data or motor commands. The functional description would explain this binding process, highlighting the system's attempt to bridge the gap between abstract thought and physical interaction. This is a cornerstone of any serious AGI effort, as purely symbolic systems are prone to the "symbol grounding problem."

Finally, the artifacts in this domain often serve a dual purpose, acting as both tutorials and validation tests. A documentation illustration showing how to create a link between two nodes in the AtomSpace is simultaneously a tutorial for new users and a specification for a developer working on the AtomSpace API. Similarly, a unit test that verifies the integrity of a graph traversal algorithm is an executable example of how to correctly navigate the knowledge graph. The following table organizes these artifacts by their function in representing and manipulating knowledge.

| Artifact Type | File/Location Example | Functional Description |
| :--- | :--- | :--- |
| **Runnable Demo** | `demos/knowledge_base/family_tree_query.py` | Loads a family tree dataset into the AtomSpace and uses MeTTa queries to answer complex relational questions (e.g., "Who are the aunts of John?"). This demonstrates pattern-based querying and inference over a structured knowledge graph. |
| **Jupyter Notebook** | `notebooks/tutorials/graph_manipulation.ipynb` | An interactive notebook showing how to programmatically create, modify, and visualize the AtomSpace graph using Python bindings. It illustrates node/link creation, attribute setting, and subgraph extraction. |
| **Documentation Illustration** | `docs/grounding_example.md` | Provides a code snippet showing how a conceptual atom `(Concept "Red Ball")` can be linked to a set of visual features extracted from an image. This illustrates the principle of symbol grounding. |
| **Unit Test** | `tests/test_atomspace_traversal.cpp` | A test that validates a breadth-first search implementation on the AtomSpace graph, ensuring it correctly visits all reachable nodes from a given starting point. This specifies the behavior of a core graph operation. |
| **Code Snippet** | `README.md` in `opencog` repository | Shows the concise syntax for asserting a new fact `(EvaluationLink (Predicate "is_parent") (List "Alice" "Charlie"))` into the AtomSpace. This serves as a quick reference for basic knowledge assertion. |

In conclusion, the artifacts in the Knowledge Representation and Manipulation domain reveal a system designed for rich, dynamic, and structured data handling. The ability to not only store vast amounts of interconnected information but also to query it flexibly and modify it procedurally is fundamental to the entire AGI project. For a clean reimplementation, these artifacts are indispensable. They provide concrete examples of how to interact with the AtomSpace, from the high-level MeTTa queries down to the low-level C++ API calls. They define the expected behavior of graph operations and provide templates for building knowledge-intensive applications. Capturing the nuances of these interactions is key to faithfully reproducing the system's core functionality.

## Probabilistic and Non-Monotonic Reasoning

A defining characteristic of the OpenCog MeTTa / Hyperon ecosystem, and a key differentiator from classical, deterministic logic systems, is its strong emphasis on uncertainty and defeasible reasoning. This capability is primarily delivered through the Probabilistic Logic Networks (PLN) subsystem [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. The artifacts in this domain—including specialized demos, academic-style papers converted into executable notebooks, and targeted unit tests—collectively paint a picture of a system engineered to make plausible, rather than certain, conclusions. This is essential for any real-world application where information is incomplete, contradictory, or subject to change. For a clean reimplementation, accurately capturing the semantics of PLN is arguably one of the most challenging and critical tasks.

The core of PLN's functionality revolves around assigning truth values to Atoms in the AtomSpace. These truth values are not simply binary true/false but are typically represented as a pair: a probability (confidence) and a strength (support). Artifacts demonstrating this feature show how facts and rules can be loaded into the AtomSpace along with their associated uncertainty metrics. For example, a demo might assert `(EvaluationLink (stv 0.9 1.1) (Predicate "is_bird") (List "Penguin"))`, indicating a high confidence that a penguin is a bird, but with a relatively weak strength of evidence. The functional description of such an artifact would detail the meaning of the `stv` (statement truth value) and how it propagates through the system. This foundational capability allows the system to reason not just with certainty, but with degrees of belief.

The most significant capability showcased is the application of PLN inference rules. These rules take atoms with their truth values as input and produce new atoms with propagated and calculated truth values as output. The provided materials suggest that there are artifacts demonstrating various PLN rules, such as Modus Ponens, Universal Instantiation, and Abduction. A runnable demo might take a general rule like `(ForAll (Predicate "man") (Predicate "mortal"))` with a high truth value and a specific fact `(Man Socrates)` with high confidence, and then apply Modus Ponens to derive `(Mortal Socrates)` with a calculated, combined truth value. The functional description must capture the mathematical formula behind the truth value propagation, as this is the essence of PLN. This demonstrates the system's ability to perform sound probabilistic inference, a cornerstone of its claim to AGI.

Non-monotonic reasoning, the ability for conclusions to be retracted in light of new evidence, is another key theme. This is naturally handled by the probabilistic nature of PLN. When new information arrives that contradicts a previously held belief, the truth value of that belief can be lowered or even falsified. An experimental notebook might simulate a belief revision scenario, where an initial assumption leads to a conclusion, and then a subsequent piece of evidence causes the system to retract that conclusion and generate a new one. The functional description would trace this entire process, highlighting the dynamic and self-correcting nature of the reasoning system. This is a critical capability for an agent operating in an unpredictable environment.

The artifacts in this domain are often more academic and theoretical than those in the core symbolic computation domain. This reflects the complexity of the underlying mathematics. A paper on PLN theory might be accompanied by a Jupyter notebook that translates the equations from the paper into executable code that manipulates AtomSpace truth values. The functional description for such a resource would need to connect the mathematical formulation in the source paper to the implementation details in the notebook. This serves as a vital bridge between theory and practice, making the complex algorithms accessible and testable. Unit tests for PLN inference rule implementations are also present, providing a rigorous specification for how each rule must behave. These tests are crucial for ensuring the correctness of a reimplementation.

The following table details the types of artifacts found in the Probabilistic and Non-Monotonic Reasoning domain.

| Artifact Type | File/Location Example | Functional Description |
| :--- | :--- | :--- |
| **Runnable Demo** | `demos/pln/modus_ponens_pln.py` | Applies a PLN Modus Ponens rule to a general mortality rule and a specific fact about Socrates. It shows the derivation of a new fact `(Mortal Socrates)` with a new, combined truth value calculated from the inputs. This demonstrates probabilistic logical inference. |
| **Jupyter Notebook** | `notebooks/theory/pln_abduction.ipynb` | Implements a PLN abduction rule to hypothesize the most likely cause of an observation. It walks through the calculation of the plausibility of different explanatory hypotheses. This illustrates abductive reasoning under uncertainty. |
| **Unit Test** | `tests/test_pln_truth_value_propagation.cpp` | Verifies that the truth value calculation for a specific PLN rule (e.g., AndLink) matches the expected result based on the rule's mathematical definition. This provides a precise, verifiable specification for the rule's logic. |
| **Documentation Illustration** | `docs/pln/truth_values.md` | Explains the structure of the STV (Strength and Confidence) truth value and provides a code snippet showing how to create and access its components in the AtomSpace. This clarifies a fundamental data structure. |
| **Code Snippet** | `examples/pln/universal_instantiation.metta` | A short MeTTa script that defines the pattern for a universal instantiation rule, showing how a quantified statement is instantiated for a specific individual. This illustrates a core PLN rule pattern. |

In summary, the artifacts in this domain are the heart of OpenCog's unique selling proposition: a reasoning system that can handle the messy, uncertain nature of real-world problems. A successful clean reimplementation cannot afford to get the details of PLN wrong, as this would break the entire paradigm. These artifacts provide the necessary blueprints, from high-level demos showing plausible reasoning in action to low-level unit tests specifying the exact mathematical behavior of each inference rule. They define the system's ability to quantify uncertainty and manage beliefs dynamically, which is a far more powerful capability than simple, binary logic.

## Planning, Decision Making, and Action Execution

While reasoning and knowledge manipulation form the cognitive core of the OpenCog MeTTa / Hyperon ecosystem, the ultimate goal is to produce intelligent behavior, which requires the capacity for planning, decision-making, and executing actions. The artifacts in this domain—primarily runnable demos and simulation-based experiments—shift the focus from static knowledge bases to dynamic, goal-directed agents. These materials, though perhaps less numerous than those in other domains, are critical for understanding how the system bridges the gap between thought and action. They demonstrate how Hyperon, the agent-building framework, orchestrates the lower-level components like the AtomSpace and PLN to formulate and carry out plans.

A primary capability showcased is single-agent planning. A recurring type of demo involves an agent tasked with navigating a maze or solving a block-world puzzle. The functional description of such a demo would outline the process: the agent begins with a representation of its current state in the AtomSpace and a high-level goal state. Using Hyperon, it then executes a planning algorithm (which might be a heuristic search like A* or a more complex process involving probabilistic reasoning). The planner explores a space of possible actions, evaluating their potential outcomes using the system's reasoning engines. For example, it might use PLN to assess the probability of success for a given action sequence. The final plan—a sequence of actions leading from the initial state to the goal—is then executed, with the agent updating its internal state in the AtomSpace after each action. This demonstrates a closed-loop cognitive architecture where perception, planning, and action are integrated.

Multi-agent planning and negotiation represent a more advanced capability. The available materials suggest that Hyperon is designed to support multiple, concurrent agents. An experimental notebook or a complex demo might simulate a scenario where two or more agents have conflicting goals and must negotiate to reach a mutually acceptable solution. The functional description would detail how each agent maintains its own private knowledge base and goals, and how Hyperon facilitates communication between them. The negotiation process might involve proposing actions, counter-proposing, and using reasoning to evaluate the fairness or utility of different agreements. This could be modeled as a game-theoretic problem where each agent seeks to maximize its own utility function, which is itself a complex expression potentially involving PLN for assessing the likelihood of achieving desired outcomes. This showcases the system's potential for building social or collaborative intelligence.

Decision-making under uncertainty is a key theme woven throughout these artifacts. In many real-world scenarios, the outcomes of actions are not guaranteed. The demos reflect this by incorporating the probabilistic nature of PLN into the decision-making process. For example, in a simulated supply chain management scenario envisioned by the company [[8](https://www.linkedin.com/posts/trueagi_trueagi-agi-supplychainintelligence-activity-7383968626653052928-wrv6)], an agent might need to decide whether to reroute a shipment. The decision would depend on probabilistic factors like the chance of a port closure, the weather forecast, and supplier reliability. The agent's reasoning engine would weigh these factors, represented as truth values in the AtomSpace, to calculate the expected utility of each possible decision. The functional description would explain this utility calculation, highlighting the integration of probabilistic inference with a decision theory framework. This demonstrates a sophisticated form of deliberative agency.

The artifacts in this domain are often simulations because they are concerned with high-level cognitive processes that can be modeled computationally. They rarely involve controlling a physical robot directly, but rather use a virtual environment as a testbed for the agent's cognitive architecture. A "robotics" demo, if it existed, would be a special case of this, where the virtual environment models a physical world. The table below outlines the types of artifacts found in this domain.

| Artifact Type | File/Location Example | Functional Description |
| :--- | :--- | :--- |
| **Runnable Demo** | `demos/planning/maze_solver_hyperon.py` | A Hyperon program that uses a heuristic search algorithm to find a path from a start to an end point in a grid-world maze. It demonstrates the cycle of perceiving the environment, planning the next move, and executing it. |
| **Simulation Experiment** | `experiments/negotiation/simple_trade.py` | Simulates a negotiation between two agents over the exchange of two resources. It shows how agents propose trades, evaluate offers using a utility function, and converge on an agreement. This illustrates multi-agent interaction. |
| **Jupyter Notebook** | `notebooks/casestudies/supply_chain_planning.ipynb` | Models a simplified supply chain where an agent must make decisions about inventory and shipping routes. It uses PLN to reason about probabilities of delays and calculates expected costs to make optimal decisions. This demonstrates planning under uncertainty. |
| **Code Snippet** | `examples/hyperon/agent_definition.hyperon` | A short Hyperon script defining the basic structure of an agent, including its goals, knowledge base, and a main loop that calls planning and action-execution functions. This serves as a template for creating new agents. |
| **Unit Test** | `tests/test_planner_heuristic.cpp` | A test that verifies the heuristic function used by a planning algorithm correctly estimates the cost to reach the goal from a given state. This specifies a component of the planning process. |

In conclusion, the artifacts in the Planning, Decision Making, and Action Execution domain reveal the system's ambition to create not just a reasoner, but an autonomous agent. They show how Hyperon provides the framework for structuring an agent's life cycle, from goal-setting to action. The deep integration with probabilistic reasoning is a standout feature, allowing agents to make pragmatic decisions in uncertain environments. For a clean reimplementation, these artifacts are essential for defining the architecture of an intelligent agent. They provide concrete examples of how to structure a planner, how to model agent interactions, and how to integrate decision-making with the rest of the cognitive stack. Without a functional planning and action-execution module, the system would remain a powerful but inert knowledge base.

## Synthesis of Capabilities for Reimplementation

This comprehensive catalog of artifacts from the `trueagi-io` repositories, organized by domain, provides a detailed blueprint of the OpenCog MeTTa / Hyperon ecosystem's intended capabilities. The analysis reveals a system conceived from the ground up for Artificial General Intelligence, with a clear philosophical divergence from dominant LLM approaches [[5](https://www.linkedin.com/posts/trueagi_trueagi-aigovernance-futureofintelligence-activity-7374793194338930688-79fV), [9](https://www.linkedin.com/posts/trueagi_trueagi-benevolentai-futureofintelligence-activity-7371568501750403072-Vomv)]. The artifacts collectively demonstrate a sophisticated, multi-layered architecture where foundational knowledge representation in the AtomSpace is orchestrated by the Hyperon language to enable complex reasoning, planning, and learning. For the explicit purpose of supporting a clean-slate reimplementation, this synthesis distills the key functional requirements and behavioral specifications derived from the available examples, demos, tests, and documentation.

The foundational layer is built upon symbolic computation primitives in the MeTTa language, which enable powerful metaprogramming and logical deduction [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. The artifacts in this domain specify the need for a robust rule-based rewriting engine capable of performing pattern matching and substitution on the AtomSpace graph. A reimplementation must accurately model the unification algorithm and provide a syntax for defining rules that can manipulate the knowledge base. The system must support not only deterministic logical inference but also, critically, the assignment and propagation of probabilistic truth values through the Probabilistic Logic Networks (PLN) subsystem. This is the most complex and defining feature of the system, requiring precise mathematical implementations of PLN inference rules whose behavior is specified in both academic papers and executable unit tests.

On top of this foundation, the system provides a rich framework for knowledge representation and manipulation. The AtomSpace is not merely a static database but a dynamic, evolving graph. The artifacts mandate that a reimplementation must provide APIs for programmatically creating, querying, and traversing this graph. Querying must be flexible, supporting complex relational patterns, while modification must be a core, first-class operation. Furthermore, the system's long-term goal of AGI necessitates a mechanism for symbol grounding, linking abstract concepts in the AtomSpace to real-world data, a capability partially addressed by the COGS subsystem [[2](https://ieeexplore.ieee.org/iel8/6287639/10820123/11096544.pdf)]. This forms the bedrock of the agent's understanding of its world.

The true power of the system is realized in its ability to translate knowledge into action through the Hyperon framework. The planning and decision-making artifacts demand a reimplementation that goes beyond passive reasoning. It must support the construction of goal-directed agents that can perceive their environment, formulate plans to achieve objectives, and execute actions. These plans must be able to incorporate probabilistic reasoning to navigate uncertainty, as demonstrated in the supply chain management case study [[8](https://www.linkedin.com/posts/trueagi_trueagi-agi-supplychainintelligence-activity-7383968626653052928-wrv6)]. The system must also support multi-agent scenarios, implying a need for frameworks for communication and negotiation between independent cognitive agents.

In summary, the full range of capabilities demonstrated by the artifacts can be synthesized into a set of core requirements for a clean reimplementation:

1.  **A Powerful Metaprogramming Engine:** A MeTTa-like language for defining rules that rewrite and reason over a symbolic knowledge base.
2.  **A Probabilistic Reasoning Engine:** A PLN implementation that correctly calculates and propagates truth values through a network of uncertain facts and rules.
3.  **A Dynamic Knowledge Graph:** An AtomSpace that supports efficient storage, querying, and modification of a large, interconnected graph of information.
4.  **A Cognitive Agent Framework:** A Hyperon-like system for defining agents, managing their goals and state, and orchestrating the above components to perform planning and decision-making.
5.  **Integrated Uncertainty Management:** A seamless integration of probabilistic reasoning into the planning and decision-making loops, allowing agents to act pragmatically in uncertain environments.
6.  **Scalable Architecture:** The underlying architecture must be designed for scalability, reflecting the ambition to handle the complexity of human-level intelligence, as proven possible by the human brain [[1](https://www.linkedin.com/posts/vishnandlall_i-read-tim-dettmers-post-on-why-agi-will-activity-7405229973583585281-POjn)].

By meticulously following the functional descriptions provided by the existing artifacts, a reimplementation can avoid the pitfalls of reinventing the wheel and instead focus on building a robust, correct, and scalable version of TrueAGI's unique and ambitious vision for AGI.